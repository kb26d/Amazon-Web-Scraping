{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# import libraries \n\nfrom bs4 import BeautifulSoup\nimport requests\nimport time\nimport datetime\n\nimport smtplib\n\n# Connect to Website and pull in data\n\nURL = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n\nheaders = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n\npage = requests.get(URL, headers=headers)\n\nsoup1 = BeautifulSoup(page.content, \"html.parser\")\n\nsoup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n\ntitle = soup2.find(id='productTitle').get_text()\n\nprice = soup2.find(id='priceblock_ourprice').get_text()\n\n# Clean up the data a little bit\n\nprice = price.strip()[1:]\ntitle = title.strip()\n\nprint(title)\nprint(price)\n\n# Create a Timestamp for your output to track when data was collected\n\nimport datetime\n\ntoday = datetime.date.today()\n\nprint(today)\n\n# Create CSV and write headers and data into the file\n\nimport csv \n\nheader = ['Title', 'Price', 'Date']\ndata = [title, price, today]\n\n\nwith open('AmazonWebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n    writer = csv.writer(f)\n    writer.writerow(header)\n    writer.writerow(data)\n\nimport pandas as pd\n\ndf = pd.read_csv(r'C:\\Users\\alexf\\AmazonWebScraperDataset.csv')\n\nprint(df)\n#Now we are appending data to the csv\n\nwith open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n    writer = csv.writer(f)\n    writer.writerow(data)\n    \n#Combine all of the above code into one function\n\n\ndef check_price():\n    URL = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n\n    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n\n    page = requests.get(URL, headers=headers)\n\n    soup1 = BeautifulSoup(page.content, \"html.parser\")\n\n    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n\n    title = soup2.find(id='productTitle').get_text()\n\n    price = soup2.find(id='priceblock_ourprice').get_text()\n\n    price = price.strip()[1:]\n    title = title.strip()\n\n    import datetime\n\n    today = datetime.date.today()\n    \n    import csv \n\n    header = ['Title', 'Price', 'Date']\n    data = [title, price, today]\n\n    with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n        writer = csv.writer(f)\n        writer.writerow(data)\n \n    \n# Runs check_price after a set time and inputs data into your CSV\n\nwhile(True):\n    check_price()\n    time.sleep(86400)\nimport pandas as pd\n\ndf = pd.read_csv(r'C:\\Users\\alexf\\AmazonWebScraperDataset.csv')\n\nprint(df)\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}